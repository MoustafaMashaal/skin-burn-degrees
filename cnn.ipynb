{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "img_length = 60\n",
    "\n",
    "def process_img(img_name):\n",
    "    img = cv2.imread(img_name)\n",
    "    \n",
    "    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    rect = (0, 0, img_length, img_length)\n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "    cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 6, cv2.GC_INIT_WITH_RECT)\n",
    "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "    img = img * mask2[:, :, np.newaxis]\n",
    "    \n",
    "    resized_img = resize(img, (img_length, img_length, 3), preserve_range=True)\n",
    "    return np.array(resized_img).astype(int)\n",
    "\n",
    "full_thickness_img_names = glob.glob('./images/full_thickness/*.jpg') + glob.glob('./images/full_thickness/*.JPG')\n",
    "X1 = [process_img(img_name) for img_name in full_thickness_img_names]\n",
    "y1 = [0] * len(X1)\n",
    "\n",
    "partial_thickness_img_names = glob.glob('./images/partial_thickness/*.jpg') + glob.glob('./images/partial_thickness/*.JPG')\n",
    "X2 = [process_img(img_name) for img_name in partial_thickness_img_names]\n",
    "y2 = [1] * len(X2)\n",
    "\n",
    "superficial_dermal_img_names = glob.glob('./images/superficial_dermal/*.jpg') + glob.glob('./images/superficial_dermal/*.JPG')\n",
    "X3 = [process_img(img_name) for img_name in superficial_dermal_img_names]\n",
    "y3 = [2] * len(X3)\n",
    "\n",
    "X = np.concatenate((X1, X2, X3))\n",
    "\n",
    "raw_y = np.concatenate((y1, y2, y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, raw_y_train, raw_y_test = train_test_split(X, raw_y, test_size=0.3)\n",
    "y_train = to_categorical(raw_y_train)\n",
    "y_test = to_categorical(raw_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/125\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 4.3844 - accuracy: 0.3409\n",
      "Epoch 2/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.0810 - accuracy: 0.4773\n",
      "Epoch 3/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 4.1426 - accuracy: 0.4091\n",
      "Epoch 4/125\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 3.1871 - accuracy: 0.3864\n",
      "Epoch 5/125\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 3.5475 - accuracy: 0.4318\n",
      "Epoch 6/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 3.3065 - accuracy: 0.5000\n",
      "Epoch 7/125\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 3.0293 - accuracy: 0.5227\n",
      "Epoch 8/125\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 1.5484 - accuracy: 0.6364\n",
      "Epoch 9/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.5167 - accuracy: 0.5227\n",
      "Epoch 10/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 1.0677 - accuracy: 0.6591\n",
      "Epoch 11/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 1.1327 - accuracy: 0.7045\n",
      "Epoch 12/125\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.7270 - accuracy: 0.7045\n",
      "Epoch 13/125\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7911 - accuracy: 0.6136\n",
      "Epoch 14/125\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5797 - accuracy: 0.7500\n",
      "Epoch 15/125\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.6828 - accuracy: 0.7727\n",
      "Epoch 16/125\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5964 - accuracy: 0.7045\n",
      "Epoch 17/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.5265 - accuracy: 0.7727\n",
      "Epoch 18/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.6497 - accuracy: 0.7045\n",
      "Epoch 19/125\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.5116 - accuracy: 0.8409\n",
      "Epoch 20/125\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4847 - accuracy: 0.8182\n",
      "Epoch 21/125\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.4806 - accuracy: 0.8409\n",
      "Epoch 22/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.8182\n",
      "Epoch 23/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.8182\n",
      "Epoch 24/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.8182\n",
      "Epoch 25/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.8182\n",
      "Epoch 26/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8409\n",
      "Epoch 27/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7727\n",
      "Epoch 28/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7955\n",
      "Epoch 29/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8409\n",
      "Epoch 30/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8409\n",
      "Epoch 31/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3750 - accuracy: 0.8182\n",
      "Epoch 32/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8182\n",
      "Epoch 33/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8409\n",
      "Epoch 34/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8636\n",
      "Epoch 35/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8636\n",
      "Epoch 36/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.7955\n",
      "Epoch 37/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.7955\n",
      "Epoch 38/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8409\n",
      "Epoch 39/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8409\n",
      "Epoch 40/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8409\n",
      "Epoch 41/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8409\n",
      "Epoch 42/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8409\n",
      "Epoch 43/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8636\n",
      "Epoch 44/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8182\n",
      "Epoch 45/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8409\n",
      "Epoch 46/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.8636\n",
      "Epoch 47/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.8636\n",
      "Epoch 48/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.8864\n",
      "Epoch 49/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.3115 - accuracy: 0.8182\n",
      "Epoch 50/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.8182\n",
      "Epoch 51/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8636\n",
      "Epoch 52/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.8864\n",
      "Epoch 53/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.8182\n",
      "Epoch 54/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8182\n",
      "Epoch 55/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8182\n",
      "Epoch 56/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2932 - accuracy: 0.8182\n",
      "Epoch 57/125\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.3085 - accuracy: 0.8182\n",
      "Epoch 58/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.3430 - accuracy: 0.7727\n",
      "Epoch 59/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.7500\n",
      "Epoch 60/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.3047 - accuracy: 0.8636\n",
      "Epoch 61/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.2718 - accuracy: 0.8636\n",
      "Epoch 62/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.3030 - accuracy: 0.8864\n",
      "Epoch 63/125\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2914 - accuracy: 0.8864\n",
      "Epoch 64/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.2742 - accuracy: 0.8636\n",
      "Epoch 65/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.2901 - accuracy: 0.8864\n",
      "Epoch 66/125\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 0.2931 - accuracy: 0.8864\n",
      "Epoch 67/125\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.2617 - accuracy: 0.80 - 0s 9ms/step - loss: 0.2930 - accuracy: 0.8182\n",
      "Epoch 68/125\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2669 - accuracy: 0.8864\n",
      "Epoch 69/125\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.3188 - accuracy: 0.7727\n",
      "Epoch 70/125\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2647 - accuracy: 0.9318\n",
      "Epoch 71/125\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.3027 - accuracy: 0.7955\n",
      "Epoch 72/125\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2803 - accuracy: 0.8409\n",
      "Epoch 73/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.2714 - accuracy: 0.8409\n",
      "Epoch 74/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2887 - accuracy: 0.8409\n",
      "Epoch 75/125\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.8409\n",
      "Epoch 76/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2672 - accuracy: 0.8636\n",
      "Epoch 77/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8864\n",
      "Epoch 78/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2687 - accuracy: 0.8409\n",
      "Epoch 79/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.2768 - accuracy: 0.8864\n",
      "Epoch 80/125\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.3240 - accuracy: 0.8182\n",
      "Epoch 81/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.2954 - accuracy: 0.8636\n",
      "Epoch 82/125\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2912 - accuracy: 0.8409\n",
      "Epoch 83/125\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2858 - accuracy: 0.8409\n",
      "Epoch 84/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.2898 - accuracy: 0.7955\n",
      "Epoch 85/125\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.2664 - accuracy: 0.8636\n",
      "Epoch 86/125\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.8864\n",
      "Epoch 87/125\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.8636\n",
      "Epoch 88/125\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.8636\n",
      "Epoch 89/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.8864\n",
      "Epoch 90/125\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 0.3013 - accuracy: 0.8182\n",
      "Epoch 91/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.2737 - accuracy: 0.8636\n",
      "Epoch 92/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.2864 - accuracy: 0.8409\n",
      "Epoch 93/125\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.5973 - accuracy: 0.8182\n",
      "Epoch 94/125\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.3161 - accuracy: 0.8636\n",
      "Epoch 95/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2643 - accuracy: 0.8864\n",
      "Epoch 96/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.8409\n",
      "Epoch 97/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.2889 - accuracy: 0.8182\n",
      "Epoch 98/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.2659 - accuracy: 0.8864\n",
      "Epoch 99/125\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.2825 - accuracy: 0.8182\n",
      "Epoch 100/125\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.3161 - accuracy: 0.7955\n",
      "Epoch 101/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.2699 - accuracy: 0.8409\n",
      "Epoch 102/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.2699 - accuracy: 0.8864\n",
      "Epoch 103/125\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2788 - accuracy: 0.8636\n",
      "Epoch 104/125\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2800 - accuracy: 0.8636\n",
      "Epoch 105/125\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2917 - accuracy: 0.8409\n",
      "Epoch 106/125\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2867 - accuracy: 0.9091\n",
      "Epoch 107/125\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2723 - accuracy: 0.8864\n",
      "Epoch 108/125\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2610 - accuracy: 0.8864\n",
      "Epoch 109/125\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.2645 - accuracy: 0.8864\n",
      "Epoch 110/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.2728 - accuracy: 0.8182\n",
      "Epoch 111/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.3083 - accuracy: 0.8409\n",
      "Epoch 112/125\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.2682 - accuracy: 0.8864\n",
      "Epoch 113/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2800 - accuracy: 0.8864\n",
      "Epoch 114/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2638 - accuracy: 0.8864\n",
      "Epoch 115/125\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.8409\n",
      "Epoch 116/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.8636\n",
      "Epoch 117/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.8409\n",
      "Epoch 118/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.2679 - accuracy: 0.8409\n",
      "Epoch 119/125\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.2896 - accuracy: 0.8636\n",
      "Epoch 120/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.2561 - accuracy: 0.8636\n",
      "Epoch 121/125\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 0.2820 - accuracy: 0.7955\n",
      "Epoch 122/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2725 - accuracy: 0.8182\n",
      "Epoch 123/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2815 - accuracy: 0.8636\n",
      "Epoch 124/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2861 - accuracy: 0.8409\n",
      "Epoch 125/125\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.2925 - accuracy: 0.7727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x131b71b10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "img_width, img_height = img_length, img_length\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=25, epochs=125, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    Full Thickness       1.00      0.73      0.85        15\n",
      " Partial Thickness       0.73      1.00      0.84        16\n",
      "Superficial Dermal       1.00      0.85      0.92        13\n",
      "\n",
      "          accuracy                           0.86        44\n",
      "         macro avg       0.91      0.86      0.87        44\n",
      "      weighted avg       0.90      0.86      0.87        44\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    Full Thickness       0.62      0.62      0.62         8\n",
      " Partial Thickness       0.57      0.57      0.57         7\n",
      "Superficial Dermal       1.00      1.00      1.00         4\n",
      "\n",
      "          accuracy                           0.68        19\n",
      "         macro avg       0.73      0.73      0.73        19\n",
      "      weighted avg       0.68      0.68      0.68        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_train_bool = np.argmax(y_pred_train, axis=1)\n",
    "print(classification_report(raw_y_train, y_pred_train_bool, target_names=['Full Thickness', 'Partial Thickness', 'Superficial Dermal']))\n",
    "      \n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_test_bool = np.argmax(y_pred_test, axis=1)\n",
    "print(classification_report(raw_y_test, y_pred_test_bool, target_names=['Full Thickness', 'Partial Thickness', 'Superficial Dermal']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
